<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <title>Audio‑reactive Head (camera bg)</title>
  <script src="https://unpkg.com/three@0.160.0/build/three.min.js"></script>
  <style>
    html,body {height:100%;margin:0;background:#000;overflow:hidden}
    #wrap{position:fixed;inset:0}
    video{position:fixed;inset:0;width:100%;height:100%;object-fit:cover;transform:scaleX(-1)} /* mirror for selfie; remove if using rear */
    #overlay{position:fixed;left:0;right:0;top:0;display:flex;justify-content:space-between;gap:8px;padding:10px;color:#fff;font:14px system-ui;background:linear-gradient(180deg,rgba(0,0,0,.5),transparent)}
    button{background:#1f6feb;color:#fff;border:0;border-radius:12px;padding:8px 12px}
  </style>
</head>
<body>
  <div id="wrap">
    <video id="cam" playsinline autoplay muted></video>
    <div id="overlay">
      <div>Tap <b>Start</b>, hold phone so the camera sees your room. The head's jaw moves to incoming audio.</div>
      <div>
        <button id="toggle">Start</button>
      </div>
    </div>
  </div>
  <script>
    let scene, camera, renderer, jaw, headGroup, rafId;
    let audioCtx, analyser, dataArray, started=false;

    async function start(){
      if(started) return;
      started = true;
      document.getElementById('toggle').textContent='Running…';

      // Ask for BOTH camera (rear if possible) and mic in one call so iOS allows it
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: { ideal: 'environment' } },
        audio: { echoCancellation: true, noiseSuppression: true }
      });

      // Camera background
      const vid = document.getElementById('cam');
      vid.srcObject = stream;

      // Audio analyser
      audioCtx = new (window.AudioContext||window.webkitAudioContext)();
      const src = audioCtx.createMediaStreamSource(stream);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 1024;
      src.connect(analyser);
      dataArray = new Uint8Array(analyser.frequencyBinCount);

      // Three.js scene
      renderer = new THREE.WebGLRenderer({alpha:true, antialias:true});
      renderer.setPixelRatio(Math.min(2, window.devicePixelRatio||1));
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.domElement.style.position='fixed';
      renderer.domElement.style.inset='0';
      document.body.appendChild(renderer.domElement);

      scene = new THREE.Scene();
      camera = new THREE.PerspectiveCamera(55, window.innerWidth/window.innerHeight, 0.01, 100);
      camera.position.set(0,0,2.2);

      // Lights
      scene.add(new THREE.AmbientLight(0xffffff, 0.6));
      const dir = new THREE.DirectionalLight(0xffffff, 0.8); dir.position.set(1,2,3); scene.add(dir);

      // Build a simple "head": sphere + separate jaw box that rotates on a hinge
      headGroup = new THREE.Group();
      scene.add(headGroup);

      const skin = new THREE.MeshStandardMaterial({color:0xffe0c0, roughness:0.6, metalness:0.0});
      const skull = new THREE.Mesh(new THREE.SphereGeometry(0.45, 32, 24), skin);
      skull.position.y = 0.05;
      headGroup.add(skull);

      // Jaw pivot: small group so rotation happens around hinge near ears
      const jawPivot = new THREE.Group();
      jawPivot.position.set(0,-0.05,0.23);
      headGroup.add(jawPivot);

      jaw = new THREE.Mesh(new THREE.BoxGeometry(0.64, 0.28, 0.38), skin);
      jaw.geometry.translate(0, -0.06, -0.14); // shift geometry so hinge feels natural
      jawPivot.add(jaw);

      // Eyes (just for life)
      const eyeMat = new THREE.MeshStandardMaterial({color:0xffffff});
      const irisMat = new THREE.MeshStandardMaterial({color:0x2222ff});
      const eyeL = new THREE.Mesh(new THREE.SphereGeometry(0.06, 16, 12), eyeMat); eyeL.position.set(-0.15,0.12,0.38);
      const eyeR = new THREE.Mesh(new THREE.SphereGeometry(0.06, 16, 12), eyeMat); eyeR.position.set(0.15,0.12,0.38);
      const irisL = new THREE.Mesh(new THREE.SphereGeometry(0.03, 12, 10), irisMat); irisL.position.set(-0.15,0.12,0.41);
      const irisR = new THREE.Mesh(new THREE.SphereGeometry(0.03, 12, 10), irisMat); irisR.position.set(0.15,0.12,0.41);
      headGroup.add(eyeL, eyeR, irisL, irisR);

      // Gentle idle motion
      let t=0;

      function loop(){
        rafId = requestAnimationFrame(loop);

        // Get audio level (simple RMS of time-domain)
        const td = new Uint8Array(analyser.fftSize);
        analyser.getByteTimeDomainData(td);
        let sum=0; for(let i=0;i<td.length;i++){ const v=(td[i]-128)/128; sum += v*v; }
        const rms = Math.sqrt(sum/td.length); // 0..~0.5

        // Map RMS to jaw open angle (clamped)
        // Smooth a bit to avoid chatter
        const open = Math.min(0.6, Math.max(0, (rms-0.02)*5));
        jaw.parent.rotation.x = THREE.MathUtils.lerp(jaw.parent.rotation.x, open, 0.25);

        // idle look
        t += 0.01; headGroup.rotation.y = Math.sin(t*0.5)*0.15;
        renderer.render(scene, camera);
      }
      loop();

      window.addEventListener('resize', ()=>{
        camera.aspect = window.innerWidth/window.innerHeight; camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
      });
    }

    document.getElementById('toggle').addEventListener('click', start);
  </script>
</body>
</html>